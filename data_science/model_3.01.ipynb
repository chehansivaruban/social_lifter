{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMj+QV7Vnm4vRcx2sy65fjy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Importing libaries"],"metadata":{"id":"lfdfW--rvkOR"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"t46Pr_ovvKW7","executionInfo":{"status":"ok","timestamp":1681384144155,"user_tz":-330,"elapsed":2602,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","source":["#Mounting Google Drive"],"metadata":{"id":"JLpljTK7voms"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPO19I6uvhBw","executionInfo":{"status":"ok","timestamp":1681384147072,"user_tz":-330,"elapsed":2921,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}},"outputId":"eac49f3f-9947-4399-a4f0-b9db39ed446b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def bad_line(x):\n","    print(x)\n","    return None\n","\n","df_data = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/final_project/data_science/data_set/topic_data_1.csv',  on_bad_lines=bad_line, engine='python')\n","\n","\n","df_data.dtypes"],"metadata":{"id":"UWRyydwkv_wP","executionInfo":{"status":"ok","timestamp":1681384152549,"user_tz":-330,"elapsed":5480,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}},"outputId":"01527346-3579-4a5e-c2c3-1672cb4c6435","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tweet                       object\n","Date                        object\n","time                        object\n","Day of week                 object\n","Cashtags                    object\n","Hashtags                    object\n","Language                    object\n","Location                      bool\n","Mentioned_users               bool\n","Followers                  float64\n","Following                  float64\n","User_created_date           object\n","Listed_count               float64\n","Favourite_count            float64\n","Tweet_count                float64\n","Verified                      bool\n","Average_favourite_count    float64\n","account_age                float64\n","Likes                      float64\n","Comments                   float64\n","Retweets                   float64\n","Views                      float64\n","clean_tweet                 object\n","subjectivity               float64\n","polarity                   float64\n","sentiment                   object\n","topics                       int64\n","key_words                   object\n","dtype: object"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df_data_linear = df_data.copy()"],"metadata":{"id":"TamJZlcvNIBF","executionInfo":{"status":"ok","timestamp":1681384163267,"user_tz":-330,"elapsed":475,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Convert \"Cashtags\" column to boolean\n","df_data_linear['Cashtags'] = np.where(df_data_linear['Cashtags'].notnull(), True, False)\n","\n","# Convert \"Hashtags\" column to boolean\n","df_data_linear['Hashtags'] = np.where(df_data_linear['Hashtags'].notnull(), True, False)\n"],"metadata":{"id":"LvW4xVKFv_4h","executionInfo":{"status":"ok","timestamp":1681384165034,"user_tz":-330,"elapsed":453,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Drop the columns we won't use for prediction\n","df_data_linear.drop(['Tweet', 'Date', 'Listed_count', 'Favourite_count', 'Tweet_count', 'User_created_date', 'Views'], axis=1, inplace=True)\n"],"metadata":{"id":"6A-2YhxLwAUK","executionInfo":{"status":"ok","timestamp":1681384170949,"user_tz":-330,"elapsed":414,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Cleaning the data for Linear regression"],"metadata":{"id":"451H2ypNI3Zv"}},{"cell_type":"markdown","source":["\n","# Convert 'time' column to numerical"],"metadata":{"id":"fSXj9FkhI8zu"}},{"cell_type":"code","source":["df_data_linear['time'] = pd.to_datetime(df_data_linear['time']).dt.hour"],"metadata":{"id":"VLLaXpzkwAdA","executionInfo":{"status":"ok","timestamp":1681384179758,"user_tz":-330,"elapsed":6741,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Encode categorical variables"],"metadata":{"id":"CaNDF1GyJeh1"}},{"cell_type":"code","source":["cat_cols = ['Day of week', 'Language', 'sentiment', 'topics', 'key_words', 'time']\n","for col in cat_cols:\n","    label_encoder = LabelEncoder()\n","    df_data_linear[col] = label_encoder.fit_transform(df_data_linear[col])\n"],"metadata":{"id":"lxA2FajrQOUC","executionInfo":{"status":"ok","timestamp":1681384182540,"user_tz":-330,"elapsed":448,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Create feature matrix with one-hot encoded categorical variables and token counts\n","vectorizer = CountVectorizer(stop_words='english')\n","vectorizer.fit(df_data_linear['clean_tweet'])\n","X_text = vectorizer.transform(df_data_linear['clean_tweet'])\n","cat_cols = ['Cashtags', 'Hashtags', 'Location', 'Mentioned_users', 'Verified', 'Day of week', 'Language', 'sentiment', 'topics', 'key_words', 'time']\n","cat_transformer = OneHotEncoder()\n","cat_transformer.fit(df_data_linear[cat_cols])\n","X_cat = cat_transformer.transform(df_data_linear[cat_cols])\n","X_num = StandardScaler().fit_transform(df_data_linear.select_dtypes(include=np.number))\n","X = np.hstack([X_cat.toarray(), X_text.toarray(), X_num])\n"],"metadata":{"id":"4Rzs4idPQQ2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Create target vectors\n","y_likes = df_data_linear['Likes']\n","y_comments = df_data_linear['Comments']\n","y_retweets = df_data_linear['Retweets']\n"],"metadata":{"id":"IH-CWMk1QUMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_likes_train, y_likes_test, y_comments_train, y_comments_test, y_retweets_train, y_retweets_test = train_test_split(X, y_likes, y_comments, y_retweets, test_size=0.2, random_state=42)"],"metadata":{"id":"_arv9JacQWpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pt6Y47VUQXqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"--f6AKkxQXoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S3bUfTrwQXjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XdnA2TCtQXg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4Ec6cAjQQXeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sNCC_DhHQXcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Vh-i20aAQXZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Cn6VzIZ1QXWm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RCD2asV7QXUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_encoder = LabelEncoder()\n","df_data_linear['Day of week'] = label_encoder.fit_transform(df_data_linear['Day of week'])\n","df_data_linear['Language'] = label_encoder.fit_transform(df_data_linear['Language'])\n","df_data_linear['sentiment'] = label_encoder.fit_transform(df_data_linear['sentiment'])\n","df_data_linear['topics'] = label_encoder.fit_transform(df_data_linear['topics'])\n","df_data_linear['key_words'] = label_encoder.fit_transform(df_data_linear['key_words'])\n","\n","\n","# create an instance of CountVectorizer with desired settings\n","vectorizer = CountVectorizer(stop_words='english')\n","\n","# fit the vectorizer to the clean_tweet column\n","vectorizer.fit(df_data_linear['clean_tweet'])\n","\n","# transform the clean_tweet column into a matrix of token counts\n","X_text = vectorizer.transform(df_data_linear['clean_tweet'])"],"metadata":{"id":"UCBcLgEIJfmQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# One-hot encode boolean variables"],"metadata":{"id":"0qcKZYcpKZ0n"}},{"cell_type":"code","source":["transformer = ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), ['Cashtags', 'Hashtags', 'Location', 'Mentioned_users', 'Verified'])], remainder='passthrough')\n","df_data_linear = pd.DataFrame(transformer.fit_transform(df_data_linear))"],"metadata":{"id":"dAzpAKZaKaYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# concatenate the one-hot encoded features, text features, and numerical features\n","X = np.concatenate((transformer.transform(df_data_linear), X_text.toarray(), df_data_linear[['Followers', 'Friends', 'time', 'Day of week', 'Language', 'sentiment']].values), axis=1)\n","\n","# scale the numerical features using StandardScaler\n","scaler = StandardScaler()\n","X[:, -6:] = scaler.fit_transform(X[:, -6:])\n","\n","# set the target variables (Likes, Comments, and Retweets)\n","y = df_data_linear[['Likes', 'Comments', 'Retweets']].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"Pmwu5x4xOaet","executionInfo":{"status":"error","timestamp":1681382886387,"user_tz":-330,"elapsed":373,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}},"outputId":"c604cfc7-66fc-427e-d7cb-8679fe482c27"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-935df27791d3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# concatenate the one-hot encoded features, text features, and numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data_linear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_data_linear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Followers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Friends'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Day of week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# scale the numerical features using StandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_names\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"columns are missing: {diff}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0;31m# ndarray was used for fitting or transforming, thus we only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: columns are missing: {'time', 'clean_tweet', 'Followers', 'key_words', 'Retweets', 'Likes', 'subjectivity', 'Average_favourite_count', 'Comments', 'Day of week', 'Following', 'sentiment', 'polarity', 'Language', 'topics', 'account_age'}"]}]}]}