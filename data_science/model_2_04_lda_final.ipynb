{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31974,"status":"ok","timestamp":1682426599918,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"YPGNLgGzKF4y","outputId":"ac17866c-c9f3-44a4-8d2f-fa28ecb1a6b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyLDAvis\n","  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy>=1.24.2\n","  Downloading numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (2.8.4)\n","Collecting funcy\n","  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (67.7.1)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.2.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (4.3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (3.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.10.1)\n","Collecting pandas>=2.0.0\n","  Downloading pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim->pyLDAvis) (6.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n","Installing collected packages: funcy, numpy, pandas, pyLDAvis\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.5.3\n","    Uninstalling pandas-1.5.3:\n","      Successfully uninstalled pandas-1.5.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n","google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed funcy-2.0 numpy-1.24.3 pandas-2.0.1 pyLDAvis-3.4.1\n"]}],"source":["!pip install pyLDAvis"]},{"cell_type":"markdown","metadata":{"id":"DQ-FGapoizd_"},"source":["#Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40020,"status":"ok","timestamp":1682867345185,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"eJMA1asLIqfL","outputId":"48b585e2-b13a-4b54-9633-1da483ef7516"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Gensim\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","from google.colab import drive\n","\n","import numpy as np\n","import pandas as pd\n","import nltk\n","nltk.download('stopwords')\n","#spacy\n","import spacy\n","from nltk.corpus import stopwords\n","\n","# #vis\n","# import pyLDAvis\n","# import pyLDAvis.gensim\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"dcwVAFK_i4hW"},"source":["#import the data set with sentiments added"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58564,"status":"ok","timestamp":1682442854240,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"8y-tMkiOKQlX","outputId":"6a655150-3aeb-4e35-a0ed-be188b8e2989"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1150394, 26)\n"]}],"source":["def bad_line(x):\n","  print(x)\n","  return None\n","\n","df_data = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/final/data_sentiment_final.csv', on_bad_lines=bad_line, engine='python')\n","print(df_data.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682771175139,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"9Jcp1JjsLsOC","outputId":"b3561a20-b707-46c9-d3e6-964f7d3b95c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["179\n"]}],"source":["stopwords = stopwords.words(\"english\")\n","print(len(stopwords))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1682442854241,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"TZYoN2A8MN1t","outputId":"604c119c-1072-41fd-a3aa-f66736cbfd25"},"outputs":[{"name":"stdout","output_type":"stream","text":["apples amp oranges eddies guitar riffs are the songs daves riffs serve the songs amazingly\n"]}],"source":["data = df_data[\"clean_tweet\"]\n","df_data['clean_tweet'] = df_data['clean_tweet'].astype(str)\n","print (data[0][0:90])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NcAuCZDeM23N"},"outputs":[],"source":["def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n","    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n","    texts_out = []\n","    for text in texts:\n","        doc = nlp(text)\n","        new_text = []\n","        for token in doc:\n","            if token.pos_ in allowed_postags:\n","                new_text.append(token.lemma_)\n","        final = \" \".join(new_text)\n","        texts_out.append(final)\n","    return (texts_out)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VFFbtywiRYn"},"outputs":[],"source":["['clean_tweet'] = df_data['clean_tweet'].astype(str)\n","split_data = np.array_split(df_data, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682442856723,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"ncjfbME9WMRx","outputId":"d87135fe-619b-4e5d-9168-3f218acc7148"},"outputs":[{"data":{"text/plain":["(115040, 26)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["split_data[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":7,"status":"error","timestamp":1682771181768,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"zKovEXJsQar8","outputId":"847651fe-6b93-4848-8f12-d7aa72b9c18b"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-8ac61b8110df>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    df_data['clean_tweet'] = gen_words(df_data['clean_tweet']\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"]}],"source":["def gen_words(texts):\n","    final = []\n","    for text in texts:\n","        new = gensim.utils.simple_preprocess(text, deacc=True)\n","        final.append(new)\n","    return (final)\n","\n","df_data['clean_tweet'] = lemmatization(df_data['clean_tweet'])\n","df_data['clean_tweet'] = gen_words(df_data['clean_tweet']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6095599,"status":"ok","timestamp":1682448952314,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"MwRe18klmVpj","outputId":"100f8e6f-c75e-4bfc-f206-e9dbe0913f0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n"]}],"source":["for i in range(0, 10):\n","    print(i)\n","    split_data[i]['clean_tweet'] = lemmatization(split_data[i]['clean_tweet'])\n","    split_data[i]['clean_tweet'] = gen_words(split_data[i]['clean_tweet'])\n","    split_data[i].to_csv(f'data_sentiment_final_lemmatized_single_topic_{i}.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"brpqoKbwjEKH"},"source":["#import the data set after lematizing"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13519,"status":"ok","timestamp":1682867366827,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"_k0OYLnCIQk_"},"outputs":[],"source":["def bad_line(x):\n","  print(x)\n","  return None\n","df_data_0 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_0.csv', on_bad_lines=bad_line, engine='python')\n","df_data_1 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_1.csv', on_bad_lines=bad_line, engine='python')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":38841,"status":"ok","timestamp":1682867405661,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"LBduNjLXjS5e"},"outputs":[],"source":["df_data_2 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_2.csv', on_bad_lines=bad_line, engine='python')\n","df_data_3 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_3.csv', on_bad_lines=bad_line, engine='python')\n","df_data_4 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_4.csv', on_bad_lines=bad_line, engine='python')\n","df_data_5 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_5.csv', on_bad_lines=bad_line, engine='python')\n","df_data_6 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_6.csv', on_bad_lines=bad_line, engine='python')\n","df_data_7 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_7.csv', on_bad_lines=bad_line, engine='python')\n","df_data_8 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_8.csv', on_bad_lines=bad_line, engine='python')\n","df_data_9 = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/year4/fyp_repo/social_lifter/data_science/data_set/final_data/data_sentiment_final_lemmatized_single_topic_9.csv', on_bad_lines=bad_line, engine='python')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1682867405663,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"q1zEBsHtVYjd","outputId":"39830e7b-2902-42a2-ea0c-fedd86607fc5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(115040, 26)"]},"metadata":{},"execution_count":4}],"source":["df_data_0.shape"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":4371,"status":"ok","timestamp":1682869612897,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"FckYxjp2SkyG"},"outputs":[],"source":["# Concatenate all dataframes into one\n","df_data = pd.concat([df_data_0, df_data_1, df_data_2, df_data_3, df_data_4, df_data_5, df_data_6, df_data_7, df_data_8, df_data_9])\n","\n","# Reset the index of the concatenated dataframe\n","df_data = df_data.reset_index(drop=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1682869617120,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"37iuAnGkUmut","outputId":"76467fab-e53d-4f8d-8917-72408138a113"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1150394, 26)"]},"metadata":{},"execution_count":26}],"source":["df_data.shape"]},{"cell_type":"code","source":["import re\n","pattern = r'[^a-zA-Z0-9\\s]'\n","# Apply the pattern to the column and replace with empty string\n","df_data['clean_tweet'] = df_data['clean_tweet'].str.replace(pattern, '')\n","\n","# Concatenate the strings in the column with a space separator\n","# df_data['clean_tweet'] = df_data['clean_tweet'].str.join(' ')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iutLsRARtPbR","executionInfo":{"status":"ok","timestamp":1682869704788,"user_tz":-330,"elapsed":12359,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}},"outputId":"9e79e2bb-13e7-4d8f-ad27-5fac51ecbfeb"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-0533526d7215>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n","  df_data['clean_tweet'] = df_data['clean_tweet'].str.replace(pattern, '')\n"]}]},{"cell_type":"code","source":["df_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"id":"Wn6rPcr2WPal","executionInfo":{"status":"ok","timestamp":1682867652151,"user_tz":-330,"elapsed":8,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}},"outputId":"894c030a-d014-4419-93e1-b2369221e073"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               Tweet                 Date  \\\n","0  @RockNRoLL_85 Apples &amp; oranges.  Eddie's g...  2023-03-25 23:59:58   \n","1  I trust Apple weather app with my life and I j...  2023-03-25 23:59:55   \n","2  @CRoss714 Apple TV is getting up there with HB...  2023-03-25 23:59:49   \n","3  The night and darkness grows as does the stren...  2023-03-25 23:59:45   \n","4  @TwoPintsJP @TheLiverPunch the grandson (my ag...  2023-03-25 23:59:40   \n","\n","       time Day of week Cashtags Hashtags Language  Location  Mentioned_users  \\\n","0  23:59:58    Saturday      NaN      NaN       en     False             True   \n","1  23:59:55    Saturday      NaN      NaN       en      True            False   \n","2  23:59:49    Saturday      NaN      NaN       en      True             True   \n","3  23:59:45    Saturday      NaN      NaN       en      True            False   \n","4  23:59:40    Saturday      NaN      NaN       en      True             True   \n","\n","   Followers  ...  Average_favourite_count account_age  Likes  Comments  \\\n","0      220.0  ...                 1.559077        11.0    0.0       0.0   \n","1      168.0  ...                 0.177647         9.0    0.0       0.0   \n","2      607.0  ...                 2.781585        13.0    1.0       1.0   \n","3      196.0  ...                 7.230292        11.0    4.0       1.0   \n","4     4449.0  ...                 0.101177        14.0    1.0       1.0   \n","\n","   Retweets  Views                                        clean_tweet  \\\n","0       0.0    9.0  apple amp orange eddy riff song dave riff serv...   \n","1       0.0  108.0  trust apple weather app life just realize only...   \n","2       0.0   57.0  apple tv get there original content severance ...   \n","3       0.0  151.0  night darkness grow strength howl wind home po...   \n","4       0.0   17.0  grandson age apple farmer own little par cours...   \n","\n","   subjectivity  polarity  sentiment  \n","0      0.900000  0.600000   positive  \n","1      0.691667  0.050000   positive  \n","2      0.683333  0.125000   positive  \n","3      0.400000 -0.300000   negative  \n","4      0.440000  0.135625   positive  \n","\n","[5 rows x 26 columns]"],"text/html":["\n","  <div id=\"df-bfc66bcd-e2ab-4fc6-9a25-fda62c574f58\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Date</th>\n","      <th>time</th>\n","      <th>Day of week</th>\n","      <th>Cashtags</th>\n","      <th>Hashtags</th>\n","      <th>Language</th>\n","      <th>Location</th>\n","      <th>Mentioned_users</th>\n","      <th>Followers</th>\n","      <th>...</th>\n","      <th>Average_favourite_count</th>\n","      <th>account_age</th>\n","      <th>Likes</th>\n","      <th>Comments</th>\n","      <th>Retweets</th>\n","      <th>Views</th>\n","      <th>clean_tweet</th>\n","      <th>subjectivity</th>\n","      <th>polarity</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@RockNRoLL_85 Apples &amp;amp; oranges.  Eddie's g...</td>\n","      <td>2023-03-25 23:59:58</td>\n","      <td>23:59:58</td>\n","      <td>Saturday</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>220.0</td>\n","      <td>...</td>\n","      <td>1.559077</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>apple amp orange eddy riff song dave riff serv...</td>\n","      <td>0.900000</td>\n","      <td>0.600000</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I trust Apple weather app with my life and I j...</td>\n","      <td>2023-03-25 23:59:55</td>\n","      <td>23:59:55</td>\n","      <td>Saturday</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>168.0</td>\n","      <td>...</td>\n","      <td>0.177647</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>108.0</td>\n","      <td>trust apple weather app life just realize only...</td>\n","      <td>0.691667</td>\n","      <td>0.050000</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@CRoss714 Apple TV is getting up there with HB...</td>\n","      <td>2023-03-25 23:59:49</td>\n","      <td>23:59:49</td>\n","      <td>Saturday</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>607.0</td>\n","      <td>...</td>\n","      <td>2.781585</td>\n","      <td>13.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>57.0</td>\n","      <td>apple tv get there original content severance ...</td>\n","      <td>0.683333</td>\n","      <td>0.125000</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The night and darkness grows as does the stren...</td>\n","      <td>2023-03-25 23:59:45</td>\n","      <td>23:59:45</td>\n","      <td>Saturday</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>196.0</td>\n","      <td>...</td>\n","      <td>7.230292</td>\n","      <td>11.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>151.0</td>\n","      <td>night darkness grow strength howl wind home po...</td>\n","      <td>0.400000</td>\n","      <td>-0.300000</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@TwoPintsJP @TheLiverPunch the grandson (my ag...</td>\n","      <td>2023-03-25 23:59:40</td>\n","      <td>23:59:40</td>\n","      <td>Saturday</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>4449.0</td>\n","      <td>...</td>\n","      <td>0.101177</td>\n","      <td>14.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>grandson age apple farmer own little par cours...</td>\n","      <td>0.440000</td>\n","      <td>0.135625</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfc66bcd-e2ab-4fc6-9a25-fda62c574f58')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bfc66bcd-e2ab-4fc6-9a25-fda62c574f58 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bfc66bcd-e2ab-4fc6-9a25-fda62c574f58');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":18843,"status":"ok","timestamp":1682867680135,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"x9Mx3g-kLyTW"},"outputs":[],"source":["# Create a dictionary of lemmatized words\n","df_data['clean_tweet'] = df_data['clean_tweet'].astype(str)\n","word_dict = corpora.Dictionary(df_data['clean_tweet'].apply(lambda x: x.split()))\n","\n","# Create a bag of words corpus\n","corpus = [word_dict.doc2bow(doc.split()) for doc in df_data['clean_tweet']]\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1663023,"status":"ok","timestamp":1682869343141,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"nANIizMsMi5M"},"outputs":[],"source":["# Train LDA model\n","lda_model = gensim.models.LdaModel(corpus=corpus,\n","                                   id2word=word_dict,\n","                                   num_topics=100, \n","                                   random_state=42,\n","                                   passes=5,\n","                                   alpha='auto',\n","                                   per_word_topics=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1273,"status":"ok","timestamp":1682869433010,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"zd8BeRZENUhA"},"outputs":[],"source":["import pickle\n","\n","# Save LDA model as a pickle file\n","with open('lda_model.pickle', 'wb') as f:\n","    pickle.dump(lda_model, f)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":574,"status":"ok","timestamp":1682869434146,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"FUOL6ClabYZr"},"outputs":[],"source":["# Save LDA model\n","lda_model.save('lda_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZ1lG1v8NYwt","executionInfo":{"status":"aborted","timestamp":1682840221251,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"outputs":[],"source":["df_data.to_csv('data_sentiment_final_lemmatized_single_topic_detected.csv', index=False)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"6UUYklGccXOL","executionInfo":{"status":"error","timestamp":1682870021249,"user_tz":-330,"elapsed":240209,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}},"outputId":"1816d201-64b4-419b-b6af-7362a1285171"},"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-27115d2bc0a4>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdoc_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msorted_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmost_probable_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_kw.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 110574 is out of bounds for axis 1 with size 110574"]}],"source":["# Create a dictionary of lemmatized words\n","df_data['clean_tweet'] = df_data['clean_tweet'].astype(str)\n","word_dict = corpora.Dictionary(df_data['clean_tweet'].apply(lambda x: x.split()))\n","\n","# Create a bag of words corpus\n","corpus = [word_dict.doc2bow(doc.split()) for doc in df_data['clean_tweet']]\n","\n","# Find the most probable topic for each document\n","topics = []\n","for doc in corpus:\n","    doc_str = ' '.join([word_dict[id] for id, freq in doc])\n","    bow = word_dict.doc2bow(doc_str.split())\n","    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0.0)\n","    sorted_topics = sorted(topic_dist, key=lambda x: x[1], reverse=True)\n","    most_probable_topic = sorted_topics[0][0]\n","    topics.append(most_probable_topic)\n","\n","# Save the topics in a new column in df_data\n","df_data['topics'] = topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXxfWN0yetZ9"},"outputs":[],"source":["df_data.head()"]},{"cell_type":"markdown","metadata":{"id":"-IXqok_OlCRT"},"source":["#usage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCAGjnal6Jno"},"outputs":[],"source":["df_data.to_csv('preprocessed_data.csv', index=False)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1682869576328,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"jcBxuHCVk9tU","outputId":"a344b60a-a6a8-4b83-bed4-12d2d7ade990"},"outputs":[{"output_type":"stream","name":"stdout","text":["The topic of the sentence is: (15, 0.122735746)\n"]}],"source":["import pickle\n","import numpy as np\n","import gensim\n","\n","# Load the LDA model\n","with open('/content/lda_model', 'rb') as f:\n","    lda_model = pickle.load(f)\n","\n","# Load the id2word dictionary\n","id2word = gensim.corpora.Dictionary.load('/content/lda_model.id2word')\n","\n","# Load the state\n","with open('/content/lda_model.state', 'rb') as f:\n","    lda_model.state = pickle.load(f)\n","\n","# Load the expElogbeta array\n","lda_model.expElogbeta = np.load('/content/lda_model.expElogbeta.npy')\n","\n","# Define the sentence to classify\n","sentence = \"Note that the regular expression pattern [^a-zA-Z0-9\\s] matches any character that is not a letter, digit, or whitespace.\"\n","\n","# Prepare the sentence for classification\n","bow = id2word.doc2bow(sentence.lower().split())\n","\n","# Classify the sentence\n","topic_dist = lda_model.get_document_topics(bow, minimum_probability=0.0)\n","topic = sorted(topic_dist, key=lambda x: x[1], reverse=True)[0]\n","\n","# Print the topic\n","print(\"The topic of the sentence is:\", topic)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"pxCAOyHWFHT0","executionInfo":{"status":"ok","timestamp":1682870659592,"user_tz":-330,"elapsed":605118,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"outputs":[],"source":["topics = []\n","for doc in corpus:\n","    doc_str = ' '.join([word_dict[id] for id, freq in doc])\n","    bow = id2word.doc2bow(doc_str.split())\n","    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0.0)\n","    sorted_topics = sorted(topic_dist, key=lambda x: x[1], reverse=True)\n","    most_probable_topic = sorted_topics[0][0]\n","    topics.append(most_probable_topic)\n","\n","# Save the topics in a new column in df_data\n","df_data['topics'] = topics"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"CFCRjiUFJ3E_","executionInfo":{"status":"ok","timestamp":1682870723586,"user_tz":-330,"elapsed":33171,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"}}},"outputs":[],"source":["df_data.to_csv('data_sentiment_final_lemmatized_single_topic_detected_final_30_04.csv', index=False)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"elapsed":389,"status":"error","timestamp":1682870877972,"user":{"displayName":"Chehan Sivaruban","userId":"13443851556090488132"},"user_tz":-330},"id":"KO-aNl7zNO7N","outputId":"fa452e4f-9e46-4f03-e527-de531c843bbe"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36m_get_topics_from_model\u001b[0;34m(model, topn)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_topics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \"\"\"\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtopics\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_lambda\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'LdaState' object has no attribute 'sstats'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-2acabece4c40>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a coherence model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcoherence_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Calculate the coherence score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, topics, texts, corpus, dictionary, window_size, keyed_vectors, coherence, topn, processes)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mtopics\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     self.model)\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mnew_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Setting topics to those of the model: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36m_get_topics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;34m\"\"\"Internal helper function to return topics from a trained topic model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_topics_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36m_get_topics_from_model\u001b[0;34m(model, topn)\u001b[0m\n\u001b[1;32m    497\u001b[0m             ]\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0;34m\"This topic model is not currently supported. Supported topic models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \" should implement the `get_topics` method.\")\n","\u001b[0;31mValueError\u001b[0m: This topic model is not currently supported. Supported topic models should implement the `get_topics` method."]}],"source":["from gensim.models import CoherenceModel\n","\n","# Create a coherence model\n","coherence_model = CoherenceModel(lda_model, corpus=corpus, dictionary=word_dict, coherence='c_v', texts=df_data['clean_tweet'])\n","\n","# Calculate the coherence score\n","coherence_score = coherence_model.get_coherence()\n","\n","print('Coherence score:', coherence_score)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyP5/QBzmi+ZhMkdam7lfX0a"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}